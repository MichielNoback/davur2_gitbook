# Data mangling with package `dplyr` {#dplyr}

```{r, include=FALSE}
knitr::opts_knit$set(cache = TRUE,
                     tidy = TRUE,
                     tidy.opts = list(blank = FALSE, width.cutoff = 60))
library(dplyr)
library(tidyr)
library(ggplot2)
library(stringr)
load("data/dose_response_long.Rdata")
dose_response_long <- as_tibble(dose_response_long)
```

This package, which is also in the tidyverse, is quite versatile. You can use it for a wide range of activities.
Some examples are  

- summarizing data; e.g. counting, ranking, 
- selecting, filtering and sampling cases
- manipulating data; creatng new or changing existing variables
- combining tables

In this chapter only a small selection of this package will be discussed.

There is an excellent cheat sheet for this package. You can find it [here](https://rstudio.com/resources/cheatsheets/). For convenience, primarily because this gitbook is also used in offline mode during examinations, I included it here as well: [dplyr-data-transformation.pdf](graphics/dplyr-data-transformation.pdf)

Before embarking on an overview of the most important functions, let's first look at the `tibble` and the `%>%` chaining operator.


The sections below are copied (and adapted) for in part from the `dplyr` and `tibble` vignettes which can be found [here](https://cran.r-project.org/web/packages/dplyr/vignettes/dplyr.html) and [here](https://cran.r-project.org/web/packages/tibble/vignettes/tibble.html)

In this chapter I will often use the term **_case_** instead of row and **_variable_** instead of column since they more precisely describe the essence. Also, these terms are used more in the tidyverse packages.

## Tibbles

Tibbles are a modern take on data frames. They keep the features that have stood the test of time, and drop the features that used to be convenient but are now frustrating (i.e. converting character vectors to factors). There is an entire package dedicated to tibbles, not surprisingle called `tibble` you usually do not have to load the ackage because dplyr and tidyr do that already (they depend on it themselves).

Use the `tibble()` constructor to create them as literals. There are several advantages over the old `data.frame` constructor:  

- It never changes an inputâ€™s type (i.e., no more `stringsAsFactors = FALSE`!).
- It never adjusts the names of variables: `name with space` does not become `name.with.space`.
- It evaluates its arguments lazily and sequentially:

    ```{r}
    tibble(x = 1:5, y = x ^ 2)
    ```

- It never uses `row.names()`. The whole point of tidy data is to store variables in a consistent way. So it never stores a variable as special attribute.
- It only recycles vectors of length 1. This is because recycling vectors of greater lengths is a frequent source of bugs.

**Coersion**
To complement `tibble()`, tibble provides `as_tibble()` to coerce objects into tibbles.

### By-row constructor
There is a third function, `tribble()` that you can use to define a table in an alternative way: row-wise.

```{r}
tribble(
  ~colA, ~colB,
  "a",   1,
  "b",   2,
  "c",   3
)
```


### Tibbles vs data frames
There are three key differences between tibbles and data frames: printing, subsetting, and recycling rules.  

**Printing**  
- When you print a tibble, it only shows the first ten rows and all the columns that fit on one screen. It also prints an abbreviated description of the column type, and uses font styles and color for highlighting.
- You can control the default appearance with options:
    - `options(tibble.print_max = n, tibble.print_min = m)`: if there are more than `n` rows, print only the first `m` rows. Use `options(tibble.print_max = Inf)` to always show all rows.
    - `options(tibble.width = Inf)` will always print all columns, regardless of the width of the screen.

**Subsetting**  
Tibbles are quite strict about subsetting. `[` always returns another tibble. Contrast this with a data frame: sometimes `[` returns a data frame and sometimes it just returns a vector.

**Recycling**  
When constructing a tibble, only values of length 1 are recycled. The first column with length different to one determines the number of rows in the tibble, conflicts lead to an error. This also extends to tibbles with zero rows, which is sometimes important for programming:

### The `str()` equivalent: `glimpse()`

The `glimpse()` function is the dplyr equivalent of `str()`:
```{r}
glimpse(dose_response_long)
```


## The chaining operator `%>%` 

In any workflow, it happens all the time that you apply some function to a dataframe, store the result in a new variable (or overwrite the first) and apply a second function to this dataframe. And so on.
There are two undesirable results with this. The first is cluttered code: many variables; how are you going to name them? Just have a look at the previous chapter and you'll understand. The second -and much worse if you are working with big dataframes- is cluttering of the environment and memory footprint.

This is where the chaining operator comes in. It helps you create clean workflows where intermediate results are only stored when opportune.

It comes down to this simple notion: `x %>% f(y))` is equivalent to f(x, y) where `f` is any function.

Here is the good old dose-response example again, converted to a tibble.

```{r}
dose_response_long
```

Suppose I want to remove cases with missing values (there aren't any - this is for the sake of argument), select the female subjects and then calculate the mean response for the two doses.
In base R, you could do something like this.

```{r}
dose_response_long_no_na <- na.omit(dose_response_long)
dose_response_long_no_na_only_female <- subset(x = dose_response_long_no_na, subset = sex == "f")
aggregate(Response ~ Dose, data = dose_response_long_no_na_only_female, FUN = mean)
```

I know, I exaggerated a bit with the variable names.

Here is the same workflow, using `dplyr`, but with the intermediate variables. It even has an explicit operation extra (`group_by()`).

```{r}
dose_response_long_no_na <- drop_na(dose_response_long)
dose_response_long_no_na_only_female <- filter(dose_response_long_no_na, sex == "f")
dose_response_long_no_na_only_female_grouped <- group_by(dose_response_long_no_na_only_female,
                                                         Dose)
summarize(dose_response_long_no_na_only_female_grouped, mean_response = mean(Response))
```

And, finally, how dplyr is supposed to be used.

```{r}
dose_response_long %>%
    drop_na() %>%
    filter(sex == "f") %>%
    group_by(Dose) %>%
    summarize(mean_response = mean(Response))
```

Isn't that a treat for your eyes? A highly readable, minimal piece of code, and what's more - no environment clogged with data you forget to clean up. 
Note that `drop_na` is actually from the tidyr package. However, it works seamlessly in the chaining context of dplyr functions.

This is the power of dplyr and the chaining operator!
If you do actually want the result stored, you only need to assign to a single variable at the beginning of the chain.  

Does it work with `ggplot2` as well? 

```{r chain-to-ggplot, fig.asp=.75, out.width='60%', fig.align='center'}
dose_response_long %>%
    drop_na() %>%
    ggplot(mapping = aes(x = sex, y = Response)) +
        geom_boxplot() +
        facet_wrap(Dose ~ .)
```

I don't know about you, but this kind of thing makes me happy!
The only thing that bothers me slightly is the `+` instead of `%>%` in ggplot2 context. 
On the other hand it is layering, not chaining what ggplot2 does, so there is clear distinction.

You have seen the essence of the tidyverse: **_clean chained workflows_**.

The sections below are copied (and adapted) for a large part from the `dplyr` vignette which can be found [here](https://cran.r-project.org/web/packages/dplyr/vignettes/dplyr.html)



Dplyr aims to provide a function for each basic verb of data manipulation:

`filter()` and `unique()` to select cases based on (the uniqueness of) their values.
`arrange()` to reorder the cases.
`select()` and `rename()` to select variables based on their names.
`mutate()` and `transmute()` to add new variables that are functions of existing variables.
`summarise()` to condense multiple values to a single value.
`sample_n()` and `sample_frac()` to take random samples.


## Selecting

### Selecting rows by index: `slice()`

If you simply want to select rows by index, use `slice()`

```{r}
slice(dose_response_long, 2:4)
```

The functions `head()` and `tail()` work as expected; they work with tibbles as well (by overloading) and in the context of chained actions.

### Get unique cases with `distinct()`

The `distinct()` function retains only unique/distinct cases from an input `tbl` or `data.frame`. You provide variables to use when determining uniqueness. If there are multiple cases for a given combination of inputs, only the first case will be preserved. If omitted, will use all variables. The `.keep_all` argument specifies whether all variables in the tbl should be kept.

```{r}
dose_response_long %>% distinct(sex, Dose, .keep_all = T)
```

```{r}
dose_response_long %>% distinct(Dose)
```

### `filter()` cases

This function is similar to the `subset` argument of the `subset()` function.

The filter function `filter()` allows you to select a subset of cases in a data frame. The first argument is the tibble or data frame. The second and subsequent arguments refer to variables within that data frame, selecting cases where the expression is TRUE.

```{r}
dose_response_long %>% filter(Dose == "dose10mg" & Response > 60)
```

When you want to filter rows based on a regular expression pattern matching a character value you can do something like the chunk below, because the only thing select needs is a logical vector.

```{r}
(t <- tibble(x = c("abb", "bbc", "dbbd", "aacc"), y = 1:4))
t %>% filter(grepl("bb", x))
```


Using `str_detect()` from the `stringr` tidyverse package this is also possible:

```{r}
t %>% filter(str_detect(x, "bb"))
```


### Selecting variables: `select()` 

This function is similar to the `select` argument of the `subset()` function.

Choose variables from a table. Closely related to `rename()` discussed below; `select()` keeps only the listed variables and `rename()` keeps all variables. 

When you use the `key = value` format this will result in a rename of the variable.

```{r}
select(dose_response_long, patient, gender = sex)
```

Use the minus sign when you want to select everything _but_ a variable:

```{r}
select(dose_response_long, -patient, -sex)
## same as 
#select(dose_response_long, -c(patient, sex))
```

You can use the colon operator to indicate a range of variables:

```{r}
select(dose_response_long, patient:Dose)
```


#### Tidyselect helpers

Both with `select()` and `rename()` you can use the special helper functions of the tidyselect package:

- `starts_with()`: Starts with a prefix.
- `ends_with()`: Ends with a suffix.
- `contains()`: Contains a literal string.
- `matches()`: Matches a regular expression.
- `num_range()`: Matches a numerical range like x01, x02, x03.
- `one_of()`: Matches variable names in a character vector.
- `everything()`: Matches all variables.
- `last_col()`: Select last variable, possibly with an offset.


```{r}
select(dose_response_long, contains("o"))
```

### Renaming variables: `rename()`

Rename variables from a table.

```{r}
dose_response_long %>% rename(Patient = patient, Gender = sex)
```

### Selecting from ranked data

The `top_n()` function makes it easy to select a few cases that based on the ranking of a value:

```{r}
dose_response_long %>% top_n(3, Response)
```

We see 4 cases returned because the third rank is the same for two cases.

This is especially interesting with grouped data:

```{r}
dose_response_long %>% group_by(Dose) %>% top_n(3, Response)
```


### Extract a colum as vector

Using `pull()` you can obtain atomic vectors.

```{r}
pull(dose_response_long, Response)
```

This is of course the same as `dose_response_long[[4]]` or `dose_response_long$Response` but the difference is that `pull()` can be applied in a `%>%` pipeline.  
With `dose_response_long[, 4]` it matters whether you are working with a tibble or a dataframe; a tibble returns a tibble and a dataframe returns a vector.

### Sorting with `arrange()`

If you want to sort the rows of a dataframe/tibble by the values of one or more columns, use `arrange()`

```{r}
dose_response_long %>% arrange(Response) %>% slice(1:3)
```

Use the function `desc()` to reverse the ordering

```{r}
dose_response_long %>% arrange(desc(Response)) %>% head(1)
```

Note that the previous chunk is equivalent to this

```{r}
dose_response_long %>% top_n(1, Response)
```

So natural oredering is from low to high, but the `top_n()` function always orders from high to low. You can reverse this as well using the `desc()` function.

### Random sampling

There are two functions available for random sampling: `sample_n()` and `sample_frac()`. 

```{r}
sample_frac(dose_response_long, 0.05, replace = TRUE)
```

The workings of `sample_n()` are obvious I guess.

## Adding and changing variables

### Window functions
A new variable is usually the result of some operation on one or more previous variables. The data in an original variables is processed such that for each old value a new value is generated. Functions that carry out this kind of operation are called **_window_** functions. Thus, window functions are functions that take a vector and return another vector of the same length.

For instance, the `cumsum()` function returns the cumulatieve sum of a numeric vector:

```{r}
cumsum(1:5)
```

Here are the main window functions. Note that some of them come from base R. Later you will see the use of several of them in contcert with the `mutate()` function.

- **_`dplyr::lead`_**  
Copy with values shifted by 1. 
    ```{r}
    lead(c(1, 4, 2, 8))
    ```

- **_`dplyr::lag`_**  
Copy with values lagged by 1. 
    ```{r}
    lag(c(1, 4, 2, 8))
    ```

- **_`dplyr::min_rank`_**   
Ranks on values, from low to high. Use `desc()` to reverse.  
    ```{r}
    min_rank(c(5, 4, 2, 8))
    ```

- **_`dplyr::ntile`_**   
Bin vector into n buckets. 
    ```{r}
    ntile(c(5, 4, 2, 8, 1), 3)
    ```

- **_`dplyr::between`_**   
Are values between a and b? 
    ```{r}
    between(c(5, 4, 2, 8, 1), 3, 5)
    ```

- **_`dplyr::cummean`_**   
Cumulative mean 
    ```{r}
    cummean(c(5, 4, 2, 8, 1))
    ```

- **_`cumsum`_**    
Cumulative sum
    ```{r}
    cumsum(c(5, 4, 2, 8, 1))
    ```

- **_`cummax`_**   
Cumulative maximum 
    ```{r}
    cummax(c(5, 4, 2, 8, 1))
    ```

- **_`cummin`_**   
Cumulative minimum 
    ```{r}
    cummin(c(5, 4, 2, 8, 1))
    ```

- **_`cumprod`_**   
Cumulative product

    ```{r}
    cumprod(c(5, 4, 2, 8, 1))
    ```

- **_`pmax`_**  
Element-wise maximum 
    ```{r}
    pmax(c(5, 4, 2, 8, 1), c(2, 2, 3, 4, 3))
    ```

- **_`pmin`_**   
Element-wise minimum

    ```{r}
    pmin(c(5, 4, 2, 8, 1), c(2, 2, 3, 4, 3))
    ```


### Add one or more variables: `mutate()`

The function `mutate()` can be used to calculate and append one or more columns.The window functions from the previous section are often-used helpers.

For instance, given the `ChickWeight` dataset which shows weight gain for `r ChickWeight %>% distinct(Chick) %>% count()` chicks:

```{r}
chicks <- as_tibble(ChickWeight) 
chicks %>% head(5)
```

Suppose we want to know the daily weight gain of these chicks (as a challenge, you could try to do this in base R).

Using `lag()` and `mutate()` this is a breeze (or so it seems):

```{r}
(chicks <- chicks %>% mutate(weight_gain = weight - lag(weight)))
```

...but the devil is in the details:

```{r}
chicks %>% slice(10:15)
```

The transition from chick 1 to chick 2 is not taken into account!
So to get the weight gain for each cick, we need to split the data first. This is dealt with in a later section but here is a preview:

```{r}
chicks <- chicks %>% 
    group_by(Chick) %>% #split on chicks
    mutate(weight_gain = weight - lag(weight)) %>% 
    ungroup() #put together again
slice(chicks, 10:15)
```

Can you use a custom function in a `mutate` context? Of course you can!

```{r}
my_z <- function(x) {
    abs((abs(x - mean(x)) / sd(x)))
}
women %>% 
    mutate(z_score = my_z(weight)) %>% 
    head()
```

And what's more, you can make multiple columns in one operation where the calculations for the subsequent columns are interdependent.

```{r}
women %>% 
    mutate(z_score = my_z(weight),
           z_bin = ntile(z_score, 3)) %>% 
    head()
```


### Create new variables based on more columns: `mutate_all()` and `mutate_at()`

The `mutate_all()` function is similar to the baser R `apply()` function.

Its syntax is a bit puzzling at first, and this has not been made easier by the introduction of new ways to code it.

Suppose you want to calculate the log2 of all numeric values in the `iris` dataset.
In base R you would probably do it like this:

```{r}
head(apply(iris[, -5], MARGIN = 2, FUN = log2))
```

When you do it with `mutate_all()` according to instructions you find all over the internet you get a warning:

```{r}
iris %>% 
    select(-Species) %>%
    mutate_all(funs(log2(.))) %>%
    head()
```

So apparently there are new improved ways to do it.




## Warning: funs() is soft deprecated as of dplyr 0.8.0
## Please use a list of either functions or lambdas: 
## 
##   # Simple named list: 
##   list(mean = mean, median = median)
## 
##   # Auto named with `tibble::lst()`: 
##   tibble::lst(mean, median)
## 
##   # Using lambdas
##   list(~ mean(., trim = .2), ~ median(., na.rm = TRUE))
## This warning is displayed once per session.


### Change a variable: `recode()` and `recode_factor()`


## Splitting



## Summarizing and counting




